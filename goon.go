/*
 * Copyright (c) 2012 Matt Jibson <matt.jibson@gmail.com>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

package goon

import (
	"errors"
	"fmt"
	"net/http"
	"reflect"
	"sync"
	"time"

	"appengine"
	"appengine/datastore"
	"appengine/memcache"
)

var (
	// LogErrors issues appengine.Context.Errorf on any error.
	LogErrors = true

	// MemcachePutTimeoutThreshold is the number of bytes at which the memcache
	// timeout uses the large setting.
	MemcachePutTimeoutThreshold = 1024 * 50
	// MemcachePutTimeoutSmall is the amount of time to wait during memcache
	// Put operations before also issuing a request to the datastore.
	MemcachePutTimeoutSmall = time.Millisecond * 5
	// MemcachePutTimeoutLarge is the amount of time to wait for large memcache
	// Put requests.
	MemcachePutTimeoutLarge = time.Millisecond * 15
	// MemcacheGetTimeout is the amount of time to wait for all memcache Get
	// requests.
	MemcacheGetTimeout = time.Millisecond * 10
)

// Goon holds the app engine context and the request memory cache.
type Goon struct {
	context       appengine.Context
	cache         map[string]interface{}
	cacheLock     sync.RWMutex // protect the cache from concurrent goroutines to speed up RPC access
	inTransaction bool
	toSet         map[string]interface{}
	toDelete      map[string]bool
}

func memkey(k *datastore.Key) string {
	return k.Encode()
}

// NewGoon creates a new Goon object from the given request.
func NewGoon(r *http.Request) *Goon {
	return FromContext(appengine.NewContext(r))
}

// FromContext creates a new Goon object from the given appengine Context.
func FromContext(c appengine.Context) *Goon {
	return &Goon{
		context: c,
		cache:   make(map[string]interface{}),
	}
}

func (g *Goon) error(err error) {
	if !LogErrors {
		return
	}
	g.context.Errorf("goon: %v", err)
}

func (g *Goon) extractKeys(src interface{}, putRequest bool) ([]*datastore.Key, error) {
	v := reflect.Indirect(reflect.ValueOf(src))
	if v.Kind() != reflect.Slice {
		return nil, fmt.Errorf("goon: value must be a slice or pointer-to-slice")
	}
	l := v.Len()

	keys := make([]*datastore.Key, l)
	for i := 0; i < l; i++ {
		vi := v.Index(i)
		key, hasStringId, err := g.getStructKey(vi.Interface())
		if err != nil {
			return nil, err
		}
		if !putRequest && key.Incomplete() {
			return nil, fmt.Errorf("goon: cannot find a key for struct - %v", vi.Interface())
		} else if putRequest && key.Incomplete() && hasStringId {
			return nil, fmt.Errorf("goon: empty string id on put")
		}
		keys[i] = key
	}
	return keys, nil
}

// Key is the same as KeyError, except nil is returned on error or if the key
// is incomplete.
func (g *Goon) Key(src interface{}) *datastore.Key {
	if k, err := g.KeyError(src); err == nil {
		return k
	}
	return nil
}

// Kind returns src's datastore Kind or "" on error.
func (g *Goon) Kind(src interface{}) string {
	if k, err := g.KeyError(src); err == nil {
		return k.Kind()
	}
	return ""
}

// KeyError returns the key of src based on its properties.
func (g *Goon) KeyError(src interface{}) (*datastore.Key, error) {
	key, _, err := g.getStructKey(src)
	return key, err
}

// RunInTransaction runs f in a transaction. It calls f with a transaction
// context tg that f should use for all App Engine operations. Neither cache nor
// memcache are used or set during a transaction.
//
// Otherwise similar to appengine/datastore.RunInTransaction:
// https://developers.google.com/appengine/docs/go/datastore/reference#RunInTransaction
func (g *Goon) RunInTransaction(f func(tg *Goon) error, opts *datastore.TransactionOptions) error {
	var ng *Goon
	err := datastore.RunInTransaction(g.context, func(tc appengine.Context) error {
		ng = &Goon{
			context:       tc,
			inTransaction: true,
			toSet:         make(map[string]interface{}),
			toDelete:      make(map[string]bool),
		}
		return f(ng)
	}, opts)

	if err == nil {
		g.cacheLock.Lock()
		defer g.cacheLock.Unlock()
		for k, v := range ng.toSet {
			g.cache[k] = v
		}

		for k := range ng.toDelete {
			delete(g.cache, k)
		}
	} else {
		g.error(err)
	}

	return err
}

// Put saves the entity src into the datastore based on src's key k. If k
// is an incomplete key, the returned key will be a unique key generated by
// the datastore.
func (g *Goon) Put(src interface{}) (*datastore.Key, error) {
	ks, err := g.PutMulti([]interface{}{src})
	if len(ks) == 1 {
		return ks[0], err
	}
	return nil, err
}

const putMultiLimit = 500

// PutMulti is a batch version of Put.
//
// src must satisfy the same conditions as the dst argument to GetMulti.
func (g *Goon) PutMulti(src interface{}) ([]*datastore.Key, error) {
	keys, err := g.extractKeys(src, true) // allow incomplete keys on a Put request
	if err != nil {
		return nil, err
	}

	var memkeys []string
	for _, key := range keys {
		if !key.Incomplete() {
			memkeys = append(memkeys, memkey(key))
		}
	}

	// Memcache needs to be updated after the datastore to prevent a common race condition
	defer memcache.DeleteMulti(g.context, memkeys)

	v := reflect.Indirect(reflect.ValueOf(src))
	multiErr, any := make(appengine.MultiError, len(keys)), false
	goroutines := (len(keys)-1)/putMultiLimit + 1
	var wg sync.WaitGroup
	wg.Add(goroutines)
	for i := 0; i < goroutines; i++ {
		go func(i int) {
			defer wg.Done()
			lo := i * putMultiLimit
			hi := (i + 1) * putMultiLimit
			if hi > len(keys) {
				hi = len(keys)
			}
			rkeys, pmerr := datastore.PutMulti(g.context, keys[lo:hi], v.Slice(lo, hi).Interface())
			if pmerr != nil {
				any = true // this flag tells PutMulti to return multiErr later
				merr, ok := pmerr.(appengine.MultiError)
				if !ok {
					g.error(pmerr)
					for j := lo; j < hi; j++ {
						multiErr[j] = pmerr
					}
					return
				}
				copy(multiErr[lo:hi], merr)
			}

			for i, key := range keys[lo:hi] {
				if multiErr[lo+i] != nil {
					continue // there was an error writing this value, go to next
				}
				vi := v.Index(lo + i).Interface()
				if key.Incomplete() {
					setStructKey(vi, rkeys[i])
					keys[i] = rkeys[i]
				}
				if g.inTransaction {
					mk := memkey(rkeys[i])
					delete(g.toDelete, mk)
					g.toSet[mk] = vi
				} else {
					g.putMemory(vi)
				}
			}
		}(i)
	}
	wg.Wait()
	if any {
		return keys, multiErr
	}
	return keys, nil
}

func (g *Goon) putMemoryMulti(src interface{}) {
	v := reflect.Indirect(reflect.ValueOf(src))
	for i := 0; i < v.Len(); i++ {
		g.putMemory(v.Index(i).Interface())
	}
}

func (g *Goon) putMemory(src interface{}) {
	key, _, _ := g.getStructKey(src)
	g.cacheLock.Lock()
	defer g.cacheLock.Unlock()
	g.cache[memkey(key)] = src
}

// FlushLocalCache clears the local memory cache.
func (g *Goon) FlushLocalCache() {
	g.cacheLock.Lock()
	g.cache = make(map[string]interface{})
	g.cacheLock.Unlock()
}

func (g *Goon) putMemcache(srcs []interface{}) error {
	items := make([]*memcache.Item, len(srcs))
	payloadSize := 0
	for i, src := range srcs {
		gob, err := toGob(src)
		if err != nil {
			g.error(err)
			return err
		}
		key, _, err := g.getStructKey(src)
		if err != nil {
			return err
		}
		// payloadSize will overflow if we push 2+ gigs on a 32bit machine
		payloadSize += len(gob)
		items[i] = &memcache.Item{
			Key:   memkey(key),
			Value: gob,
		}
	}
	memcacheTimeout := MemcachePutTimeoutSmall
	if payloadSize >= MemcachePutTimeoutThreshold {
		memcacheTimeout = MemcachePutTimeoutLarge
	}
	errc := make(chan error, 1) // need to buffer so as to not leak a goroutine
	go func() {
		errc <- memcache.SetMulti(g.context, items)
	}()
	g.putMemoryMulti(srcs)
	select {
	case err := <-errc:
		if err != nil {
			g.error(err)
		}
		// since putMemcache() gives no guarantee it will actually store the data in memcache
		// we log and swallow this error
	case <-time.After(memcacheTimeout):
		return TimeoutError{"memcache", "put"}
	}
	return nil
}

// Get loads the entity based on dst's key into dst
// If there is no such entity for the key, Get returns
// datastore.ErrNoSuchEntity.
func (g *Goon) Get(dst interface{}) error {
	set := reflect.ValueOf(dst)
	if set.Kind() != reflect.Ptr {
		return fmt.Errorf("goon: expected pointer to a struct, got %#v", dst)
	}
	set = set.Elem()
	if !set.CanSet() {
		return errors.New(fmt.Sprintf("goon: provided %#v, which cannot be changed", dst))
	}
	dsts := reflect.Indirect(reflect.New(reflect.SliceOf(reflect.TypeOf(dst))))
	dsts = reflect.Append(dsts, reflect.ValueOf(dst))
	if err := g.GetMulti(dsts.Interface()); err != nil {
		// Look for an embedded error if it's multi
		if me, ok := err.(appengine.MultiError); ok {
			for i, merr := range me {
				if i == 0 {
					return merr
				}
			}
		}
		// Not multi, normal error
		return err
	}
	set.Set(reflect.Indirect(dsts.Index(0)))
	return nil
}

const getMultiLimit = 1000

// GetMulti is a batch version of Get.
//
// dst has similar constraints as datastore.GetMulti.
func (g *Goon) GetMulti(dst interface{}) error {
	keys, err := g.extractKeys(dst, false) // don't allow incomplete keys on a Get request
	if err != nil {
		return err
	}

	if g.inTransaction {
		// todo: support getMultiLimit in transactions
		return datastore.GetMulti(g.context, keys, dst)
	}

	var memkeys []string // a slice of datastore.Key.Encode() that is not in the local cache
	var mixs []int       // a slice of indexes of dst that represent the memkeys

	var dskeys []*datastore.Key // a slice of datastore.Key that should be fetched by the datastore
	var dsdst []interface{}     // a slice of pointers to the destination objects to be filled, index lines up with dskeys
	var dixs []int              // a slice of indexes of dst that represent the dskeys

	v := reflect.Indirect(reflect.ValueOf(dst))
	g.cacheLock.RLock()
	for i, key := range keys {
		m := memkey(key)
		vi := v.Index(i)
		if s, present := g.cache[m]; present {
			reflect.Indirect(v.Index(i)).Set(reflect.Indirect(reflect.ValueOf(s)))
		} else {
			memkeys = append(memkeys, m)
			mixs = append(mixs, i)
			dskeys = append(dskeys, key)
			dsdst = append(dsdst, vi.Interface())
			dixs = append(dixs, i)
		}
	}
	g.cacheLock.RUnlock()

	if len(memkeys) == 0 { // everything was fetched from local cache, return
		return nil
	}

	memcacheChan := make(chan map[string]*memcache.Item, 1) // buffer so that we don't leak a goroutine if the request times out
	datastoreChan := make(chan error, 1)                    // again, buffer so we don't leak go routine
	datastoreStarted := false
	copyValues := true

	go func() {
		memvalues, err := memcache.GetMulti(g.context, memkeys)
		if err != nil {
			g.error(err)
		}
		memcacheChan <- memvalues
	}()
	memcacheGetTimeoutChan := time.After(MemcacheGetTimeout)
	for {
		select {
		case memvalues := <-memcacheChan: // memcache has returned
			// write fetched entries to dst
			for i, m := range memkeys {
				if s, present := memvalues[m]; present {
					d := v.Index(mixs[i])
					if d.Kind() == reflect.Struct {
						d = d.Addr()
					}
					err := fromGob(d.Interface(), s.Value)
					if err != nil {
						g.error(err)
						return err
					}
					g.putMemory(d.Interface()) // populate local cache
				}
			}

			if len(memkeys) == len(memvalues) { // memcache got a hit on every key
				return nil
			}

			if !datastoreStarted {
				datastoreStarted = true
				// datastore hasn't been kicked off yet
				// reset it, populate it, and kick off the request
				// since we're not making copies of the destination structs, datastore.GetMulti() will write in the values
				copyValues = false
				if len(memvalues) != 0 { // no memcache results
					// ds fields already indexed in initial local cache lookup
					dskeys = dskeys[:0]
					dsdst = dsdst[:0]
					dixs = dixs[:0]
					for i, m := range memkeys {
						if _, present := memvalues[m]; !present {
							// memcache miss
							d := v.Index(mixs[i]).Interface()
							dskeys = append(dskeys, keys[mixs[i]])
							dsdst = append(dsdst, d)
							dixs = append(dixs, mixs[i])
						}
					}
				}
				go g.startDatastoreGetMulti(datastoreChan, len(keys), dskeys, dsdst, dixs)
			}
		case err := <-datastoreChan:
			// since all errors will be multiError, need to copy partial results before returning
			if copyValues { // datastore request was started before memcache returned
				for i, dsti := range dixs {
					err := setStructKey(dsdst[i], dskeys[i])
					if err != nil {
						return err
					}
					v.Index(dsti).Set(reflect.ValueOf(dsdst[i]))
				}
			}
			return err
		case <-memcacheGetTimeoutChan:
			if !datastoreStarted { //memcache took too long, start the datastore request
				// memcache.GetMulti() could potentially be writing to the dst objects
				// to address a race condition, we need to make copies to send  to
				// the datastore
				datastoreStarted = true
				copyValues = true
				g.cacheLock.RLock()
				for i, key := range keys {
					if _, present := g.cache[memkey(key)]; !present {
						dskeys = append(dskeys, key)
						dixs = append(dixs, i)
						dsdst = append(dsdst, reflect.New(reflect.TypeOf(v.Index(i).Elem().Interface())).Interface())
					}
				}
				g.cacheLock.RUnlock()
				go g.startDatastoreGetMulti(datastoreChan, len(keys), dskeys, dsdst, dixs)
			} // else - do nothing, datastore request already started
		}
	}
}
func (g *Goon) startDatastoreGetMulti(datastoreChan chan error, fullLength int, dskeys []*datastore.Key, dsdst []interface{}, dixs []int) {
	multiErr, any := make(appengine.MultiError, fullLength), false
	goroutines := (len(dskeys)-1)/getMultiLimit + 1
	var wg sync.WaitGroup
	wg.Add(goroutines)
	for i := 0; i < goroutines; i++ {
		go func(i int) {
			defer wg.Done()
			var toCache []interface{}
			lo := i * getMultiLimit
			hi := (i + 1) * getMultiLimit
			if hi > len(dskeys) {
				hi = len(dskeys)
			}
			gmerr := datastore.GetMulti(g.context, dskeys[lo:hi], dsdst[lo:hi])
			if gmerr != nil {
				any = true // this flag tells GetMulti to return multiErr later
				merr, ok := gmerr.(appengine.MultiError)
				if !ok {
					g.error(gmerr)
					for j := lo; j < hi; j++ {
						multiErr[j] = gmerr
					}
					return
				}
				for i, idx := range dixs[lo:hi] {
					if merr[i] == nil {
						toCache = append(toCache, dsdst[lo+i])
					} else {
						multiErr[idx] = merr[i]
					}
				}
			} else {
				toCache = append(toCache, dsdst[lo:hi]...)
			}
			if len(toCache) > 0 {
				if err := g.putMemcache(toCache); err != nil {
					g.error(err)
					// since putMemcache() gives no guarantee it will actually store the data in memcache
					// we log and swallow this error
				}
			}
		}(i)
	}
	wg.Wait()
	if any {
		datastoreChan <- multiErr
	} else {
		datastoreChan <- nil
	}
}

// Delete deletes the entity for the given key.
func (g *Goon) Delete(key *datastore.Key) error {
	keys := []*datastore.Key{key}
	return g.DeleteMulti(keys)
}

const deleteMultiLimit = 500

// DeleteMulti is a batch version of Delete.
func (g *Goon) DeleteMulti(keys []*datastore.Key) error {
	if len(keys) == 0 {
		return nil
		// not an error, and it was "successful", so return nil
	}
	memkeys := make([]string, len(keys))

	g.cacheLock.Lock()
	for i, k := range keys {
		mk := memkey(k)
		memkeys[i] = mk

		if g.inTransaction {
			delete(g.toSet, mk)
			g.toDelete[mk] = true
		} else {
			delete(g.cache, mk)
		}
	}
	g.cacheLock.Unlock()

	// Memcache needs to be updated after the datastore to prevent a common race condition
	defer memcache.DeleteMulti(g.context, memkeys)

	multiErr, any := make(appengine.MultiError, len(keys)), false
	goroutines := (len(keys)-1)/deleteMultiLimit + 1
	var wg sync.WaitGroup
	wg.Add(goroutines)
	for i := 0; i < goroutines; i++ {
		go func(i int) {
			defer wg.Done()
			lo := i * deleteMultiLimit
			hi := (i + 1) * deleteMultiLimit
			if hi > len(keys) {
				hi = len(keys)
			}
			dmerr := datastore.DeleteMulti(g.context, keys[lo:hi])
			if dmerr != nil {
				any = true // this flag tells DeleteMulti to return multiErr later
				merr, ok := dmerr.(appengine.MultiError)
				if !ok {
					g.error(dmerr)
					for j := lo; j < hi; j++ {
						multiErr[j] = dmerr
					}
					return
				}
				copy(multiErr[lo:hi], merr)
			}
		}(i)
	}
	wg.Wait()
	if any {
		return multiErr
	}
	return nil
}

// NotFound returns true if err is an appengine.MultiError and err[idx] is a datastore.ErrNoSuchEntity.
func NotFound(err error, idx int) bool {
	if merr, ok := err.(appengine.MultiError); ok {
		return idx < len(merr) && merr[idx] == datastore.ErrNoSuchEntity
	}
	return false
}

// TimeoutError is the type returned by goon.TimeoutContext's Call method when an
// API call times out
// When passed to the appengine.IsTimeoutError(err) function it returns true
type TimeoutError struct {
	service, method string
}

func (e TimeoutError) Error() string {
	return e.service + "." + e.method + " - Request timed out"
}

func (e TimeoutError) IsTimeout() bool {
	return true
}
